{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Байесовская классификация спам/не спам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.feature_extraction.text as tx, sklearn.naive_bayes as nb, sklearn.linear_model as lm, sklearn.ensemble as en, sklearn.metrics as me, sklearn.model_selection as ms\n",
    "from warnings import filterwarnings as fw\n",
    "fw('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнаем вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('Н')%3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем корпус текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('SMSpam.csv')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем количество слов по классам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего строк: 5572 \n",
      "Из них 747 spam и 4825 ham \n",
      "Всего слов:  87265 \n",
      "из них 17788 spam и 69477 ham\n"
     ]
    }
   ],
   "source": [
    "cnt, cntS, cntH = 0, 0, 0\n",
    "for i in corpus['Message']:\n",
    "    cnt += len(i.split(' '))\n",
    "for i in corpus[corpus['Category']=='spam']['Message']:\n",
    "    cntS += len(i.split(' '))\n",
    "for i in corpus[corpus['Category']=='ham']['Message']:\n",
    "    cntH += len(i.split(' '))\n",
    "print('Всего строк:', corpus.shape[0], '\\nИз них', \n",
    "    corpus['Category'].value_counts()['spam'], 'spam и',corpus['Category'].value_counts()['ham'], 'ham', \n",
    "    '\\nВсего слов: ', cnt, '\\nиз них', cntS, 'spam и', cntH, 'ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: (4457,) \n",
      "Тестовая выборка (1115,)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = ms.train_test_split(corpus['Message'],corpus['Category'], test_size=0.2)\n",
    "print('Обучающая выборка:', xtrain.shape,'\\nТестовая выборка', xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем все слова с учетом регистра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 10857 токенов\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(lowercase=False)\n",
    "cv.fit(corpus['Message'])\n",
    "print('Всего', len(cv.vocabulary_.keys()), 'токенов')\n",
    "\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97563   0.99792   0.98665       963\n",
      "        spam    0.98462   0.84211   0.90780       152\n",
      "\n",
      "    accuracy                        0.97668      1115\n",
      "   macro avg    0.98012   0.92001   0.94723      1115\n",
      "weighted avg    0.97686   0.97668   0.97590      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96976   0.99896   0.98414       963\n",
      "        spam    0.99187   0.80263   0.88727       152\n",
      "\n",
      "    accuracy                        0.97220      1115\n",
      "   macro avg    0.98081   0.90080   0.93571      1115\n",
      "weighted avg    0.97277   0.97220   0.97094      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99354   0.95846   0.97569       963\n",
      "        spam    0.78495   0.96053   0.86391       152\n",
      "\n",
      "    accuracy                        0.95874      1115\n",
      "   macro avg    0.88924   0.95949   0.91980      1115\n",
      "weighted avg    0.96511   0.95874   0.96045      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr =  lm.LogisticRegression()\n",
    "rfc = en.RandomForestClassifier()\n",
    "cnb = nb.ComplementNB()\n",
    "\n",
    "lr.fit(tr_xtrain,ytrain)\n",
    "rfc.fit(tr_xtrain,ytrain)\n",
    "cnb.fit(tr_xtrain,ytrain)\n",
    "\n",
    "pred_lr = lr.predict(tr_xtest)\n",
    "pred_rfc = rfc.predict(tr_xtest)\n",
    "pred_cnb = cnb.predict(tr_xtest)\n",
    "\n",
    "print('Логистическая регрессия: \\n', me.classification_report(ytest, pred_lr, digits=5),\n",
    "    'Случайный лес: \\n', me.classification_report(ytest, pred_rfc, digits=5),\n",
    "    'Наивный Байес: \\n', me.classification_report(ytest, pred_cnb, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем все слова, но в одном регистре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 8709 токенов\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer()\n",
    "cv.fit(corpus['Message'])\n",
    "print('Всего', len(cv.vocabulary_.keys()), 'токенов')\n",
    "\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98063   0.99896   0.98971       963\n",
      "        spam    0.99254   0.87500   0.93007       152\n",
      "\n",
      "    accuracy                        0.98206      1115\n",
      "   macro avg    0.98658   0.93698   0.95989      1115\n",
      "weighted avg    0.98225   0.98206   0.98158      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97172   0.99896   0.98515       963\n",
      "        spam    0.99200   0.81579   0.89531       152\n",
      "\n",
      "    accuracy                        0.97399      1115\n",
      "   macro avg    0.98186   0.90738   0.94023      1115\n",
      "weighted avg    0.97448   0.97399   0.97290      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99257   0.97092   0.98163       963\n",
      "        spam    0.83815   0.95395   0.89231       152\n",
      "\n",
      "    accuracy                        0.96861      1115\n",
      "   macro avg    0.91536   0.96244   0.93697      1115\n",
      "weighted avg    0.97152   0.96861   0.96945      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr =  lm.LogisticRegression()\n",
    "rfc = en.RandomForestClassifier()\n",
    "cnb = nb.ComplementNB()\n",
    "\n",
    "lr.fit(tr_xtrain,ytrain)\n",
    "rfc.fit(tr_xtrain,ytrain)\n",
    "cnb.fit(tr_xtrain,ytrain)\n",
    "\n",
    "pred_lr = lr.predict(tr_xtest)\n",
    "pred_rfc = rfc.predict(tr_xtest)\n",
    "pred_cnb = cnb.predict(tr_xtest)\n",
    "\n",
    "print('Логистическая регрессия: \\n', me.classification_report(ytest, pred_lr, digits=5),\n",
    "    'Случайный лес: \\n', me.classification_report(ytest, pred_rfc, digits=5),\n",
    "    'Наивный Байес: \\n', me.classification_report(ytest, pred_cnb, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Найдем все стоп-слова, которые встречаются в большом количестве сообщений (более 500 , что около 9% всей выборки) и уберем их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 15 токенов\n",
      "{'to', 'of', 'you', 'have', 'and', 'for', 'the', 'in', 'it', 'that', 'me', 'is', 'call', 'your', 'my'}\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(max_df = 500)\n",
    "cv.fit(corpus['Message'])\n",
    "stop = cv.stop_words_\n",
    "print('Всего', len(stop), 'токенов')\n",
    "print(stop)\n",
    "\n",
    "cv = tx.CountVectorizer(analyzer = 'word', stop_words = stop)\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97859   0.99688   0.98765       963\n",
      "        spam    0.97761   0.86184   0.91608       152\n",
      "\n",
      "    accuracy                        0.97848      1115\n",
      "   macro avg    0.97810   0.92936   0.95187      1115\n",
      "weighted avg    0.97846   0.97848   0.97790      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97169   0.99792   0.98463       963\n",
      "        spam    0.98413   0.81579   0.89209       152\n",
      "\n",
      "    accuracy                        0.97309      1115\n",
      "   macro avg    0.97791   0.90686   0.93836      1115\n",
      "weighted avg    0.97338   0.97309   0.97202      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99357   0.96262   0.97785       963\n",
      "        spam    0.80220   0.96053   0.87425       152\n",
      "\n",
      "    accuracy                        0.96233      1115\n",
      "   macro avg    0.89788   0.96157   0.92605      1115\n",
      "weighted avg    0.96748   0.96233   0.96373      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr =  lm.LogisticRegression()\n",
    "rfc = en.RandomForestClassifier()\n",
    "cnb = nb.ComplementNB()\n",
    "\n",
    "lr.fit(tr_xtrain,ytrain)\n",
    "rfc.fit(tr_xtrain,ytrain)\n",
    "cnb.fit(tr_xtrain,ytrain)\n",
    "\n",
    "pred_lr = lr.predict(tr_xtest)\n",
    "pred_rfc = rfc.predict(tr_xtest)\n",
    "pred_cnb = cnb.predict(tr_xtest)\n",
    "\n",
    "print('Логистическая регрессия: \\n', me.classification_report(ytest, pred_lr, digits=5),\n",
    "    'Случайный лес: \\n', me.classification_report(ytest, pred_rfc, digits=5),\n",
    "    'Наивный Байес: \\n', me.classification_report(ytest, pred_cnb, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем все стоп-слова, которые встречаются в маленьком количестве сообщений (менее 10, что около 0.18% всей выборки), отфильтруем только те слова, которые не характерны какому-то классу (разница в частотах по классам не более, чем в 5 раз):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 7691 токенов отмечены как редкие.\n",
      "Из них 358 удовлетворяют условиям.\n",
      "Работаем с 8709 - 358 = 8351 токенами.\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(min_df = 10)\n",
    "cv.fit(corpus['Message'])\n",
    "stop = cv.stop_words_\n",
    "print('Всего', len(stop), 'токенов отмечены как редкие.')\n",
    "#print(stop) # не будем выводить список слов, так как он слишком большой\n",
    "\n",
    "all_spam = corpus[corpus['Category']=='spam'].groupby('Category').agg({'Message':' '.join}).to_string()\n",
    "all_ham = corpus[corpus['Category']=='ham'].groupby('Category').agg({'Message':' '.join}).to_string()\n",
    "temp = set()\n",
    "for i in stop:\n",
    "    frH = all_ham.count(i + ' ')/cntH\n",
    "    frS = all_spam.count(i + ' ')/cntS\n",
    "    if(frS != 0 and frH != 0):\n",
    "        if(not(frS/frH > 5 or frS/frH < 0.2)):\n",
    "            temp.add(i)\n",
    "stop = temp\n",
    "print('Из них {0} удовлетворяют условиям.'.format(len(stop)))\n",
    "\n",
    "cv = tx.CountVectorizer(analyzer = 'word', stop_words = stop)\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "print('Работаем с {0} - {1} = {2}'.format(len(cv.vocabulary_) + len(stop), len(stop), len(cv.vocabulary_)), 'токенами.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = tx.CountVectorizer(stop_words = stop)\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98163   0.99896   0.99022       963\n",
      "        spam    0.99259   0.88158   0.93380       152\n",
      "\n",
      "    accuracy                        0.98296      1115\n",
      "   macro avg    0.98711   0.94027   0.96201      1115\n",
      "weighted avg    0.98313   0.98296   0.98253      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97467   0.99896   0.98667       963\n",
      "        spam    0.99219   0.83553   0.90714       152\n",
      "\n",
      "    accuracy                        0.97668      1115\n",
      "   macro avg    0.98343   0.91724   0.94690      1115\n",
      "weighted avg    0.97706   0.97668   0.97583      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99258   0.97300   0.98270       963\n",
      "        spam    0.84795   0.95395   0.89783       152\n",
      "\n",
      "    accuracy                        0.97040      1115\n",
      "   macro avg    0.92027   0.96347   0.94026      1115\n",
      "weighted avg    0.97287   0.97040   0.97113      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr =  lm.LogisticRegression()\n",
    "rfc = en.RandomForestClassifier()\n",
    "cnb = nb.ComplementNB()\n",
    "\n",
    "lr.fit(tr_xtrain,ytrain)\n",
    "rfc.fit(tr_xtrain,ytrain)\n",
    "cnb.fit(tr_xtrain,ytrain)\n",
    "\n",
    "pred_lr = lr.predict(tr_xtest)\n",
    "pred_rfc = rfc.predict(tr_xtest)\n",
    "pred_cnb = cnb.predict(tr_xtest)\n",
    "\n",
    "print('Логистическая регрессия: \\n', me.classification_report(ytest, pred_lr, digits=5),\n",
    "    'Случайный лес: \\n', me.classification_report(ytest, pred_rfc, digits=5),\n",
    "    'Наивный Байес: \\n', me.classification_report(ytest, pred_cnb, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенный список стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97864   0.99896   0.98869       963\n",
      "        spam    0.99242   0.86184   0.92254       152\n",
      "\n",
      "    accuracy                        0.98027      1115\n",
      "   macro avg    0.98553   0.93040   0.95561      1115\n",
      "weighted avg    0.98052   0.98027   0.97968      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97270   0.99896   0.98566       963\n",
      "        spam    0.99206   0.82237   0.89928       152\n",
      "\n",
      "    accuracy                        0.97489      1115\n",
      "   macro avg    0.98238   0.91066   0.94247      1115\n",
      "weighted avg    0.97534   0.97489   0.97388      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99344   0.94289   0.96750       963\n",
      "        spam    0.72637   0.96053   0.82720       152\n",
      "\n",
      "    accuracy                        0.94529      1115\n",
      "   macro avg    0.85990   0.95171   0.89735      1115\n",
      "weighted avg    0.95703   0.94529   0.94837      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(stop_words = 'english')\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "\n",
    "lr =  lm.LogisticRegression()\n",
    "rfc = en.RandomForestClassifier()\n",
    "cnb = nb.ComplementNB()\n",
    "\n",
    "lr.fit(tr_xtrain,ytrain)\n",
    "rfc.fit(tr_xtrain,ytrain)\n",
    "cnb.fit(tr_xtrain,ytrain)\n",
    "\n",
    "pred_lr = lr.predict(tr_xtest)\n",
    "pred_rfc = rfc.predict(tr_xtest)\n",
    "pred_cnb = cnb.predict(tr_xtest)\n",
    "\n",
    "print('Логистическая регрессия: \\n', me.classification_report(ytest, pred_lr, digits=5),\n",
    "    'Случайный лес: \\n', me.classification_report(ytest, pred_rfc, digits=5),\n",
    "    'Наивный Байес: \\n', me.classification_report(ytest, pred_cnb, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем только слова с высокой важностью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739910313901345"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = tx.CountVectorizer()\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "\n",
    "e = en.RandomForestClassifier()\n",
    "e.fit(tr_xtrain,ytrain)\n",
    "e.score(tr_xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.87545   1.00000   0.93359       963\n",
      "        spam    1.00000   0.09868   0.17964       152\n",
      "\n",
      "    accuracy                        0.87713      1115\n",
      "   macro avg    0.93773   0.54934   0.55662      1115\n",
      "weighted avg    0.89243   0.87713   0.83081      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.87785   1.00000   0.93495       963\n",
      "        spam    1.00000   0.11842   0.21176       152\n",
      "\n",
      "    accuracy                        0.87982      1115\n",
      "   macro avg    0.93892   0.55921   0.57336      1115\n",
      "weighted avg    0.89450   0.87982   0.83636      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.87882   0.98650   0.92955       963\n",
      "        spam    0.61765   0.13816   0.22581       152\n",
      "\n",
      "    accuracy                        0.87085      1115\n",
      "   macro avg    0.74823   0.56233   0.57768      1115\n",
      "weighted avg    0.84321   0.87085   0.83361      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imp = pd.DataFrame({'name' : cv.vocabulary_.keys(), 'importance' : e.feature_importances_}) \n",
    "imp = imp.sort_values(by = 'importance', ascending = False)\n",
    "top100 = imp.head(n=100)['name'].to_numpy()\n",
    "\n",
    "cv = tx.CountVectorizer(vocabulary = top100)\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "\n",
    "lr =  lm.LogisticRegression()\n",
    "rfc = en.RandomForestClassifier()\n",
    "cnb = nb.ComplementNB()\n",
    "\n",
    "lr.fit(tr_xtrain,ytrain)\n",
    "rfc.fit(tr_xtrain,ytrain)\n",
    "cnb.fit(tr_xtrain,ytrain)\n",
    "\n",
    "pred_lr = lr.predict(tr_xtest)\n",
    "pred_rfc = rfc.predict(tr_xtest)\n",
    "pred_cnb = cnb.predict(tr_xtest)\n",
    "\n",
    "print('Логистическая регрессия: \\n', me.classification_report(ytest, pred_lr, digits=5),\n",
    "    'Случайный лес: \\n', me.classification_report(ytest, pred_rfc, digits=5),\n",
    "    'Наивный Байес: \\n', me.classification_report(ytest, pred_cnb, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем tf-idf векторизатор слов в одном регистре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfv = tx.TfidfVectorizer()\n",
    "tfidfv.fit(corpus['Message'])\n",
    "tr_xtrain = tfidfv.transform(xtrain)\n",
    "tr_xtest = tfidfv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.95912   0.99896   0.97864       963\n",
      "        spam    0.99107   0.73026   0.84091       152\n",
      "\n",
      "    accuracy                        0.96233      1115\n",
      "   macro avg    0.97510   0.86461   0.90977      1115\n",
      "weighted avg    0.96348   0.96233   0.95986      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97368   0.99896   0.98616       963\n",
      "        spam    0.99213   0.82895   0.90323       152\n",
      "\n",
      "    accuracy                        0.97578      1115\n",
      "   macro avg    0.98291   0.91395   0.94469      1115\n",
      "weighted avg    0.97620   0.97578   0.97485      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98845   0.97715   0.98277       963\n",
      "        spam    0.86503   0.92763   0.89524       152\n",
      "\n",
      "    accuracy                        0.97040      1115\n",
      "   macro avg    0.92674   0.95239   0.93900      1115\n",
      "weighted avg    0.97162   0.97040   0.97084      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr =  lm.LogisticRegression()\n",
    "rfc = en.RandomForestClassifier()\n",
    "cnb = nb.ComplementNB()\n",
    "\n",
    "lr.fit(tr_xtrain,ytrain)\n",
    "rfc.fit(tr_xtrain,ytrain)\n",
    "cnb.fit(tr_xtrain,ytrain)\n",
    "\n",
    "pred_lr = lr.predict(tr_xtest)\n",
    "pred_rfc = rfc.predict(tr_xtest)\n",
    "pred_cnb = cnb.predict(tr_xtest)\n",
    "\n",
    "print('Логистическая регрессия: \\n', me.classification_report(ytest, pred_lr, digits=5),\n",
    "    'Случайный лес: \\n', me.classification_report(ytest, pred_rfc, digits=5),\n",
    "    'Наивный Байес: \\n', me.classification_report(ytest, pred_cnb, digits=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2a2d0a56c23e8ff240e12265c41bd4cf4ebc4a5bdfa5544f52816f127301f16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
