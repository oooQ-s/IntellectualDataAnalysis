{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.feature_extraction.text as tx, sklearn.naive_bayes as nb, sklearn.linear_model as lm, sklearn.ensemble as en, sklearn.metrics as me, sklearn.model_selection as ms\n",
    "from warnings import filterwarnings as fw\n",
    "fw('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "все слова с учетом регистра<br>\n",
    "все в одном регистре<br>\n",
    "без стоп слов<br>\n",
    "выделение специфичных для классов<br>\n",
    "-- -- \n",
    "лог регрессия, случайный лес, байес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('Н')%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitpredict(xtrain,ytrain,xtest,ytest):\n",
    "    \n",
    "    lr =  lm.LogisticRegression()\n",
    "    rfc = en.RandomForestClassifier()\n",
    "    cnb = nb.ComplementNB()\n",
    "\n",
    "    lr.fit(xtrain,ytrain)\n",
    "    rfc.fit(xtrain,ytrain)\n",
    "    cnb.fit(xtrain,ytrain)\n",
    "\n",
    "    pred_lr = lr.predict(xtest)\n",
    "    pred_rfc = rfc.predict(xtest)\n",
    "    pred_cnb = cnb.predict(xtest)\n",
    "    \n",
    "    print('Логистическая регрессия: \\n', me.classification_report(ytest, pred_lr, digits=5),\n",
    "        'Случайный лес: \\n', me.classification_report(ytest, pred_rfc, digits=5),\n",
    "        'Наивный Байес: \\n', me.classification_report(ytest, pred_cnb, digits=5))\n",
    "    \n",
    "    return lr, rfc, cnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('SMSpam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего строк: 5572 \n",
      "Из них 747 spam и 4825 ham \n",
      "Всего слов:  87265 \n",
      "из них 17788 spam и 69477 ham\n"
     ]
    }
   ],
   "source": [
    "cnt, cntS, cntH = 0, 0, 0\n",
    "for i in corpus['Message']:\n",
    "    cnt += len(i.split(' '))\n",
    "for i in corpus[corpus['Category']=='spam']['Message']:\n",
    "    cntS += len(i.split(' '))\n",
    "for i in corpus[corpus['Category']=='ham']['Message']:\n",
    "    cntH += len(i.split(' '))\n",
    "print('Всего строк:', corpus.shape[0], '\\nИз них', \n",
    "    corpus['Category'].value_counts()['spam'], 'spam и',corpus['Category'].value_counts()['ham'], 'ham', \n",
    "    '\\nВсего слов: ', cnt, '\\nиз них', cntS, 'spam и', cntH, 'ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: (4457,) \n",
      "Тестовая выборка (1115,)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = ms.train_test_split(corpus['Message'],corpus['Category'], test_size=0.2)\n",
    "print('Обучающая выборка:', xtrain.shape,'\\nТестовая выборка', xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем все слова с учетом регистра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 10857 токенов\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(lowercase=False)\n",
    "cv.fit(corpus['Message'])\n",
    "print('Всего', len(cv.vocabulary_.keys()), 'токенов')\n",
    "\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98381   0.99897   0.99133       973\n",
      "        spam    0.99213   0.88732   0.93680       142\n",
      "\n",
      "    accuracy                        0.98475      1115\n",
      "   macro avg    0.98797   0.94315   0.96407      1115\n",
      "weighted avg    0.98487   0.98475   0.98439      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98281   0.99897   0.99083       973\n",
      "        spam    0.99206   0.88028   0.93284       142\n",
      "\n",
      "    accuracy                        0.98386      1115\n",
      "   macro avg    0.98744   0.93963   0.96183      1115\n",
      "weighted avg    0.98399   0.98386   0.98344      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99464   0.95375   0.97377       973\n",
      "        spam    0.75275   0.96479   0.84568       142\n",
      "\n",
      "    accuracy                        0.95516      1115\n",
      "   macro avg    0.87369   0.95927   0.90972      1115\n",
      "weighted avg    0.96383   0.95516   0.95745      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем все слова, но в одном регистре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 8709 токенов\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer()\n",
    "cv.fit(corpus['Message'])\n",
    "print('Всего', len(cv.vocabulary_.keys()), 'токенов')\n",
    "\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98577   0.99692   0.99131       973\n",
      "        spam    0.97710   0.90141   0.93773       142\n",
      "\n",
      "    accuracy                        0.98475      1115\n",
      "   macro avg    0.98144   0.94916   0.96452      1115\n",
      "weighted avg    0.98467   0.98475   0.98449      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97887   1.00000   0.98932       973\n",
      "        spam    1.00000   0.85211   0.92015       142\n",
      "\n",
      "    accuracy                        0.98117      1115\n",
      "   macro avg    0.98944   0.92606   0.95474      1115\n",
      "weighted avg    0.98156   0.98117   0.98051      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99577   0.96711   0.98123       973\n",
      "        spam    0.81176   0.97183   0.88462       142\n",
      "\n",
      "    accuracy                        0.96771      1115\n",
      "   macro avg    0.90377   0.96947   0.93292      1115\n",
      "weighted avg    0.97233   0.96771   0.96893      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Найдем все стоп-слова, которые встречаются в большом количестве сообщений (более 500 , что около 9% всей выборки) и уберем их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 15 токенов\n",
      "{'to', 'me', 'that', 'is', 'of', 'for', 'have', 'it', 'and', 'the', 'your', 'you', 'call', 'my', 'in'}\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(max_df = 500)\n",
    "cv.fit(corpus['Message'])\n",
    "stop = cv.stop_words_\n",
    "print('Всего', len(stop), 'токенов')\n",
    "print(stop)\n",
    "\n",
    "cv = tx.CountVectorizer(analyzer = 'word', stop_words = stop)\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98580   0.99897   0.99234       973\n",
      "        spam    0.99225   0.90141   0.94465       142\n",
      "\n",
      "    accuracy                        0.98655      1115\n",
      "   macro avg    0.98902   0.95019   0.96850      1115\n",
      "weighted avg    0.98662   0.98655   0.98627      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97885   0.99897   0.98881       973\n",
      "        spam    0.99180   0.85211   0.91667       142\n",
      "\n",
      "    accuracy                        0.98027      1115\n",
      "   macro avg    0.98533   0.92554   0.95274      1115\n",
      "weighted avg    0.98050   0.98027   0.97962      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99576   0.96506   0.98017       973\n",
      "        spam    0.80233   0.97183   0.87898       142\n",
      "\n",
      "    accuracy                        0.96592      1115\n",
      "   macro avg    0.89904   0.96844   0.92957      1115\n",
      "weighted avg    0.97112   0.96592   0.96728      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем все стоп-слова, которые встречаются в маленьком количестве сообщений (менее 10, что около 0.18% всей выборки) и уберем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 7691 токенов отмечены как стоп-слова.\n",
      "Работаем с 8709 - 7691 = 1018 токенами.\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(min_df = 10)\n",
    "cv.fit(corpus['Message'])\n",
    "stop = cv.stop_words_\n",
    "print('Всего', len(stop), 'токенов отмечены как стоп-слова.')\n",
    "#print(stop) // не будем выводить список слов, так как он слишком большой\n",
    "\n",
    "cv = tx.CountVectorizer(analyzer = 'word', stop_words = stop)\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "print('Работаем с {0} - {1} = {2}'.format(len(cv.vocabulary_) + len(stop), len(stop), len(cv.vocabulary_)), 'токенами.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98577   0.99692   0.99131       973\n",
      "        spam    0.97710   0.90141   0.93773       142\n",
      "\n",
      "    accuracy                        0.98475      1115\n",
      "   macro avg    0.98144   0.94916   0.96452      1115\n",
      "weighted avg    0.98467   0.98475   0.98449      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98278   0.99692   0.98980       973\n",
      "        spam    0.97656   0.88028   0.92593       142\n",
      "\n",
      "    accuracy                        0.98206      1115\n",
      "   macro avg    0.97967   0.93860   0.95786      1115\n",
      "weighted avg    0.98198   0.98206   0.98166      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99265   0.97122   0.98182       973\n",
      "        spam    0.82822   0.95070   0.88525       142\n",
      "\n",
      "    accuracy                        0.96861      1115\n",
      "   macro avg    0.91043   0.96096   0.93353      1115\n",
      "weighted avg    0.97171   0.96861   0.96952      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенный список стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98283   1.00000   0.99134       973\n",
      "        spam    1.00000   0.88028   0.93633       142\n",
      "\n",
      "    accuracy                        0.98475      1115\n",
      "   macro avg    0.99141   0.94014   0.96383      1115\n",
      "weighted avg    0.98502   0.98475   0.98433      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97883   0.99794   0.98830       973\n",
      "        spam    0.98374   0.85211   0.91321       142\n",
      "\n",
      "    accuracy                        0.97937      1115\n",
      "   macro avg    0.98129   0.92503   0.95075      1115\n",
      "weighted avg    0.97946   0.97937   0.97873      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99678   0.95581   0.97587       973\n",
      "        spam    0.76374   0.97887   0.85802       142\n",
      "\n",
      "    accuracy                        0.95874      1115\n",
      "   macro avg    0.88026   0.96734   0.91695      1115\n",
      "weighted avg    0.96710   0.95874   0.96086      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(stop_words = 'english')\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем только слова с высокой важностью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838565022421525"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = tx.CountVectorizer()\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "\n",
    "e = en.RandomForestClassifier()\n",
    "e.fit(tr_xtrain,ytrain)\n",
    "e.score(tr_xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.95379   0.99692   0.97487       973\n",
      "        spam    0.96939   0.66901   0.79167       142\n",
      "\n",
      "    accuracy                        0.95516      1115\n",
      "   macro avg    0.96159   0.83297   0.88327      1115\n",
      "weighted avg    0.95577   0.95516   0.95154      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96414   0.99486   0.97926       973\n",
      "        spam    0.95495   0.74648   0.83794       142\n",
      "\n",
      "    accuracy                        0.96323      1115\n",
      "   macro avg    0.95955   0.87067   0.90860      1115\n",
      "weighted avg    0.96297   0.96323   0.96126      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97204   0.89311   0.93091       973\n",
      "        spam    0.52941   0.82394   0.64463       142\n",
      "\n",
      "    accuracy                        0.88430      1115\n",
      "   macro avg    0.75072   0.85853   0.78777      1115\n",
      "weighted avg    0.91567   0.88430   0.89445      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = pd.DataFrame({'name' : cv.vocabulary_.keys(), 'importance' : e.feature_importances_}) \n",
    "imp = imp.sort_values(by = 'importance', ascending = False)\n",
    "top100 = imp.head(n=1000)['name'].to_numpy()\n",
    "\n",
    "cv = tx.CountVectorizer(vocabulary = top100)\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "\n",
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем tf-idf векторизатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfv = tx.TfidfVectorizer()\n",
    "tfidfv.fit(corpus['Message'])\n",
    "tr_xtrain = tfidfv.transform(xtrain)\n",
    "tr_xtest = tfidfv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96524   0.99897   0.98182       973\n",
      "        spam    0.99074   0.75352   0.85600       142\n",
      "\n",
      "    accuracy                        0.96771      1115\n",
      "   macro avg    0.97799   0.87625   0.91891      1115\n",
      "weighted avg    0.96849   0.96771   0.96579      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98184   1.00000   0.99084       973\n",
      "        spam    1.00000   0.87324   0.93233       142\n",
      "\n",
      "    accuracy                        0.98386      1115\n",
      "   macro avg    0.99092   0.93662   0.96158      1115\n",
      "weighted avg    0.98415   0.98386   0.98338      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98956   0.97431   0.98187       973\n",
      "        spam    0.84076   0.92958   0.88294       142\n",
      "\n",
      "    accuracy                        0.96861      1115\n",
      "   macro avg    0.91516   0.95194   0.93241      1115\n",
      "weighted avg    0.97061   0.96861   0.96928      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2a2d0a56c23e8ff240e12265c41bd4cf4ebc4a5bdfa5544f52816f127301f16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
