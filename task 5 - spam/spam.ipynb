{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.feature_extraction.text as tx, sklearn.naive_bayes as nb, sklearn.linear_model as lm, sklearn.ensemble as en, sklearn.metrics as me, sklearn.model_selection as ms\n",
    "from warnings import filterwarnings as fw\n",
    "fw('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "все слова с учетом регистра<br>\n",
    "все в одном регистре<br>\n",
    "без стоп слов<br>\n",
    "выделение специфичных для классов<br>\n",
    "-- -- \n",
    "лог регрессия, случайный лес, байес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('Н')%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitpredict(xtrain,ytrain,xtest,ytest):\n",
    "    \n",
    "    lr =  lm.LogisticRegression()\n",
    "    rfc = en.RandomForestClassifier()\n",
    "    cnb = nb.ComplementNB()\n",
    "\n",
    "    lr.fit(xtrain,ytrain)\n",
    "    rfc.fit(xtrain,ytrain)\n",
    "    cnb.fit(xtrain,ytrain)\n",
    "\n",
    "    pred_lr = lr.predict(xtest)\n",
    "    pred_rfc = rfc.predict(xtest)\n",
    "    pred_cnb = cnb.predict(xtest)\n",
    "    \n",
    "    print('Логистическая регрессия: \\n', me.classification_report(ytest, pred_lr, digits=5),\n",
    "        'Случайный лес: \\n', me.classification_report(ytest, pred_rfc, digits=5),\n",
    "        'Наивный Байес: \\n', me.classification_report(ytest, pred_cnb, digits=5))\n",
    "    \n",
    "    return lr, rfc, cnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('SMSpam.csv')\n",
    "corpus['Message'] = corpus['Message'].str.replace(r'[^\\w\\s]+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего строк: 5572 \n",
      "Из них 747 spam и 4825 ham \n",
      "Всего слов:  87265 \n",
      "из них 17788 spam и 69477 ham\n"
     ]
    }
   ],
   "source": [
    "cnt, cntS, cntH = 0, 0, 0\n",
    "for i in corpus['Message']:\n",
    "    cnt += len(i.split(' '))\n",
    "for i in corpus[corpus['Category']=='spam']['Message']:\n",
    "    cntS += len(i.split(' '))\n",
    "for i in corpus[corpus['Category']=='ham']['Message']:\n",
    "    cntH += len(i.split(' '))\n",
    "print('Всего строк:', corpus.shape[0], '\\nИз них', \n",
    "    corpus['Category'].value_counts()['spam'], 'spam и',corpus['Category'].value_counts()['ham'], 'ham', \n",
    "    '\\nВсего слов: ', cnt, '\\nиз них', cntS, 'spam и', cntH, 'ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: (4457,) \n",
      "Тестовая выборка (1115,)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = ms.train_test_split(corpus['Message'],corpus['Category'], test_size=0.2)\n",
    "print('Обучающая выборка:', xtrain.shape,'\\nТестовая выборка', xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем все слова с учетом регистра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 11596 токенов\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(lowercase=False)\n",
    "cv.fit(corpus['Message'])\n",
    "print('Всего', len(cv.vocabulary_.keys()), 'токенов')\n",
    "\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97446   0.99687   0.98554       957\n",
      "        spam    0.97794   0.84177   0.90476       158\n",
      "\n",
      "    accuracy                        0.97489      1115\n",
      "   macro avg    0.97620   0.91932   0.94515      1115\n",
      "weighted avg    0.97496   0.97489   0.97409      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96960   1.00000   0.98457       957\n",
      "        spam    1.00000   0.81013   0.89510       158\n",
      "\n",
      "    accuracy                        0.97309      1115\n",
      "   macro avg    0.98480   0.90506   0.93984      1115\n",
      "weighted avg    0.97391   0.97309   0.97189      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99023   0.95298   0.97125       957\n",
      "        spam    0.76804   0.94304   0.84659       158\n",
      "\n",
      "    accuracy                        0.95157      1115\n",
      "   macro avg    0.87913   0.94801   0.90892      1115\n",
      "weighted avg    0.95874   0.95157   0.95358      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем все слова, но в одном регистре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 9542 токенов\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer()\n",
    "cv.fit(corpus['Message'])\n",
    "print('Всего', len(cv.vocabulary_.keys()), 'токенов')\n",
    "\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.97546   0.99687   0.98605       957\n",
      "        spam    0.97810   0.84810   0.90847       158\n",
      "\n",
      "    accuracy                        0.97578      1115\n",
      "   macro avg    0.97678   0.92248   0.94726      1115\n",
      "weighted avg    0.97583   0.97578   0.97505      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96569   1.00000   0.98255       957\n",
      "        spam    1.00000   0.78481   0.87943       158\n",
      "\n",
      "    accuracy                        0.96951      1115\n",
      "   macro avg    0.98285   0.89241   0.93099      1115\n",
      "weighted avg    0.97055   0.96951   0.96793      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98813   0.95716   0.97240       957\n",
      "        spam    0.78191   0.93038   0.84971       158\n",
      "\n",
      "    accuracy                        0.95336      1115\n",
      "   macro avg    0.88502   0.94377   0.91106      1115\n",
      "weighted avg    0.95891   0.95336   0.95501      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Найдем стоп-слова и уберем их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 204 токенов\n"
     ]
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(max_df=0.01)\n",
    "cv.fit(corpus['Message'])\n",
    "stop = cv.stop_words_\n",
    "print('Всего', len(stop), 'токенов')\n",
    "#print(stop)\n",
    "\n",
    "cv = tx.CountVectorizer(analyzer = 'word', stop_words = stop)\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.95892   1.00000   0.97903       957\n",
      "        spam    1.00000   0.74051   0.85091       158\n",
      "\n",
      "    accuracy                        0.96323      1115\n",
      "   macro avg    0.97946   0.87025   0.91497      1115\n",
      "weighted avg    0.96474   0.96323   0.96087      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96468   0.99896   0.98152       957\n",
      "        spam    0.99194   0.77848   0.87234       158\n",
      "\n",
      "    accuracy                        0.96771      1115\n",
      "   macro avg    0.97831   0.88872   0.92693      1115\n",
      "weighted avg    0.96854   0.96771   0.96605      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99309   0.90073   0.94466       957\n",
      "        spam    0.61538   0.96203   0.75062       158\n",
      "\n",
      "    accuracy                        0.90942      1115\n",
      "   macro avg    0.80424   0.93138   0.84764      1115\n",
      "weighted avg    0.93957   0.90942   0.91716      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем встроенный список стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96862   1.00000   0.98406       957\n",
      "        spam    1.00000   0.80380   0.89123       158\n",
      "\n",
      "    accuracy                        0.97220      1115\n",
      "   macro avg    0.98431   0.90190   0.93764      1115\n",
      "weighted avg    0.97307   0.97220   0.97091      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96667   1.00000   0.98305       957\n",
      "        spam    1.00000   0.79114   0.88339       158\n",
      "\n",
      "    accuracy                        0.97040      1115\n",
      "   macro avg    0.98333   0.89557   0.93322      1115\n",
      "weighted avg    0.97139   0.97040   0.96893      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.99330   0.92999   0.96060       957\n",
      "        spam    0.69406   0.96203   0.80637       158\n",
      "\n",
      "    accuracy                        0.93453      1115\n",
      "   macro avg    0.84368   0.94601   0.88349      1115\n",
      "weighted avg    0.95090   0.93453   0.93875      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = tx.CountVectorizer(stop_words = 'english')\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем только слова с высокой важностью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9704035874439462"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = tx.CountVectorizer()\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "\n",
    "e = en.RandomForestClassifier()\n",
    "e.fit(tr_xtrain,ytrain)\n",
    "e.score(tr_xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.91715   0.99478   0.95439       957\n",
      "        spam    0.93506   0.45570   0.61277       158\n",
      "\n",
      "    accuracy                        0.91839      1115\n",
      "   macro avg    0.92611   0.72524   0.78358      1115\n",
      "weighted avg    0.91969   0.91839   0.90598      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.93558   0.98642   0.96033       957\n",
      "        spam    0.87736   0.58861   0.70455       158\n",
      "\n",
      "    accuracy                        0.93004      1115\n",
      "   macro avg    0.90647   0.78751   0.83244      1115\n",
      "weighted avg    0.92733   0.93004   0.92408      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96175   0.89342   0.92633       957\n",
      "        spam    0.54867   0.78481   0.64583       158\n",
      "\n",
      "    accuracy                        0.87803      1115\n",
      "   macro avg    0.75521   0.83911   0.78608      1115\n",
      "weighted avg    0.90322   0.87803   0.88658      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = pd.DataFrame({'name' : cv.vocabulary_.keys(), 'importance' : e.feature_importances_}) \n",
    "imp = imp.sort_values(by = 'importance', ascending = False)\n",
    "top100 = imp.head(n=1000)['name'].to_numpy()\n",
    "\n",
    "cv = tx.CountVectorizer(vocabulary = top100)\n",
    "cv.fit(corpus['Message'])\n",
    "tr_xtrain = cv.transform(xtrain)\n",
    "tr_xtest = cv.transform(xtest)\n",
    "\n",
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- -- \n",
    "Используем tf-idf векторизатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfv = tx.TfidfVectorizer()\n",
    "tfidfv.fit(corpus['Message'])\n",
    "tr_xtrain = tfidfv.transform(xtrain)\n",
    "tr_xtest = tfidfv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.95319   1.00000   0.97603       957\n",
      "        spam    1.00000   0.70253   0.82528       158\n",
      "\n",
      "    accuracy                        0.95785      1115\n",
      "   macro avg    0.97659   0.85127   0.90066      1115\n",
      "weighted avg    0.95982   0.95785   0.95467      1115\n",
      " Случайный лес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.96862   1.00000   0.98406       957\n",
      "        spam    1.00000   0.80380   0.89123       158\n",
      "\n",
      "    accuracy                        0.97220      1115\n",
      "   macro avg    0.98431   0.90190   0.93764      1115\n",
      "weighted avg    0.97307   0.97220   0.97091      1115\n",
      " Наивный Байес: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham    0.98620   0.97074   0.97841       957\n",
      "        spam    0.83815   0.91772   0.87613       158\n",
      "\n",
      "    accuracy                        0.96323      1115\n",
      "   macro avg    0.91217   0.94423   0.92727      1115\n",
      "weighted avg    0.96522   0.96323   0.96392      1115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), RandomForestClassifier(), ComplementNB())"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitpredict(tr_xtrain, ytrain, tr_xtest, ytest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2a2d0a56c23e8ff240e12265c41bd4cf4ebc4a5bdfa5544f52816f127301f16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
